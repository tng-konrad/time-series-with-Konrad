{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aee873fe",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3988895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import warnings\n",
    "\n",
    "# Third-party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing, Holt, SimpleExpSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Configuration\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46aa491",
   "metadata": {},
   "source": [
    "This code imports the necessary libraries for time series analysis and visualization in Python.\n",
    "\n",
    "First, `import warnings` brings in the `warnings` module. This is used to manage warning messages that might appear during code execution.  Often these are informational but can clutter output; we’ll see how it’s used shortly to suppress certain types of warnings.\n",
    "\n",
    "Next, several third-party libraries are imported:\n",
    "\n",
    "*   `import matplotlib.pyplot as plt`: `matplotlib` is a powerful plotting library. We import its `pyplot` module and give it the alias `plt`, which is standard practice. This allows us to create charts and graphs easily.\n",
    "*   `import numpy as np`:  `numpy` provides support for numerical operations, especially with arrays. It's fundamental for many scientific computing tasks in Python. We use the alias `np`.\n",
    "*   `import pandas as pd`: `pandas` is a library built on top of NumPy that provides data structures like DataFrames, which are excellent for working with tabular data (like time series).  The alias `pd` is standard.\n",
    "*   `from sklearn.metrics import mean_absolute_error, mean_squared_error`: This imports specific functions from the `sklearn` (scikit-learn) library. These functions (`mean_absolute_error` and `mean_squared_error`) are used to evaluate the accuracy of our time series forecasting models by calculating how close our predictions are to the actual values.\n",
    "*   `from statsmodels.graphics.tsaplots import plot_acf, plot_pacf`:  `statsmodels` is a library focused on statistical modeling. Here we're importing functions for visualizing *autocorrelation* and *partial autocorrelation*. These plots (`plot_acf`, `plot_pacf`) are crucial tools for understanding the relationships within a time series and choosing appropriate models.\n",
    "*   `from statsmodels.tsa.holtwinters import ExponentialSmoothing, Holt, SimpleExpSmoothing`: This imports classes from `statsmodels` that implement different *exponential smoothing* methods. These are common techniques for forecasting time series data.  `ExponentialSmoothing` is a general class, while `Holt` and `SimpleExpSmoothing` represent specific variations of the technique.\n",
    "*   `from statsmodels.tsa.seasonal import seasonal_decompose`: This imports a function that allows us to break down a time series into its constituent parts: trend, seasonality, and residual (random noise).  This is helpful for understanding the underlying patterns in the data.\n",
    "\n",
    "Finally, there are two configuration lines:\n",
    "\n",
    "*   `warnings.simplefilter(action='ignore', category=FutureWarning)`: This line tells Python to ignore `FutureWarning` messages. These warnings indicate that a feature you're using might be deprecated (removed) in a future version of the library.  While it’s good practice to eventually update your code, ignoring these can keep output cleaner during initial exploration.\n",
    "*   `plt.style.use('fivethirtyeight')`: This sets the visual style for `matplotlib` plots to 'fivethirtyeight'. This is a pre-defined style that provides a specific look and feel (color scheme, font sizes, etc.) often used in data visualizations.  It's purely aesthetic and doesn’t affect the functionality of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122895d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    SEASONAL_PERIOD = 12\n",
    "    ACF_LAGS = 12\n",
    "    data_folder = './data/'\n",
    "    img_dim1 = 20\n",
    "    img_dim2 = 10\n",
    "    SEED = 42\n",
    "\n",
    "# display style \n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "plt.rcParams[\"figure.figsize\"] = (CFG.img_dim1, CFG.img_dim2)\n",
    "\n",
    "\n",
    "np.random.seed(CFG.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887920c0",
   "metadata": {},
   "source": [
    "This code defines a configuration class and sets up some display settings for plotting. \n",
    "\n",
    "First, the `class CFG:` block creates a class named `CFG`. This is a common practice in Python to group related constants or parameters together. Think of it as a container for settings that will be used throughout your program. Inside this class:\n",
    "\n",
    "*   `SEASONAL_PERIOD = 12`:  This defines a constant representing the length of the seasonal cycle in your time series data. A value of 12 suggests monthly seasonality (like yearly patterns repeating every 12 months).\n",
    "*   `ACF_LAGS = 12`: This sets the number of lags to consider when calculating the Autocorrelation Function (ACF). The ACF helps identify how strongly past values are correlated with current values in a time series.  Using 12 lags means we'll look at correlations up to 12 time periods into the past.\n",
    "*   `data_folder = './data/'`: This specifies the path to the directory where your time series data is stored. The `./` indicates the current working directory, so it’s looking for a folder named “data” within the same location as your Python script.\n",
    "*   `img_dim1 = 20` and `img_dim2 = 10`: These define the dimensions (width and height) of the plots you'll be creating using `matplotlib`.  \n",
    "*   `SEED = 42`: This sets a seed for the random number generator. Setting a seed ensures that any random processes in your code (like data shuffling or initialization) will produce the same results every time you run it.  This is important for reproducibility – meaning others can verify your work. The value 42 is often used as a default, but any integer will work.\n",
    "\n",
    "Following the class definition:\n",
    "\n",
    "*   `plt.style.use(\"seaborn-v0_8\")`: This line changes the visual style of `matplotlib` plots to \"seaborn-v0_8\". Seaborn is another Python visualization library that builds on top of Matplotlib and provides a more aesthetically pleasing default style.  The “v0\\_8” specifies a particular version of the seaborn style.\n",
    "*   `plt.rcParams[\"figure.figsize\"] = (CFG.img_dim1, CFG.img_dim2)`: This line sets the default size of all figures created with `matplotlib`. It uses the values defined in the `CFG` class for the width (`img_dim1`) and height (`img_dim2`).  `plt.rcParams` is a dictionary-like object that controls various aspects of Matplotlib's behavior.\n",
    "*   `np.random.seed(CFG.SEED)`: This sets the seed for NumPy’s random number generator, using the value defined in the `CFG` class (`SEED`).  As mentioned earlier, this ensures reproducibility of any random operations performed with NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443bcbe1",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e146d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"MAE\": float(round(mean_absolute_error(y_true, y_pred), 2)),\n",
    "        \"RMSE\": float(round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110ae4e",
   "metadata": {},
   "source": [
    "This function `forecast_metrics` calculates and returns common error metrics used to evaluate the accuracy of time series forecasts. It's very similar to a previous version, but with added formatting for cleaner output.  \n",
    "\n",
    "*   `def forecast_metrics(y_true, y_pred):`: This defines a function named `forecast_metrics` that takes two arguments:\n",
    "    *   `y_true`:  This represents the actual (observed) values of your time series. It's typically a NumPy array or Pandas Series.\n",
    "    *   `y_pred`: This represents the predicted values generated by your forecasting model. It should have the same length as `y_true`.\n",
    "\n",
    "*   `return { ... }`: The function returns a dictionary containing the calculated error metrics. Dictionaries are useful for storing key-value pairs, making it easy to access specific metrics by their names.\n",
    "\n",
    "*   `\"MAE\": float(round(mean_absolute_error(y_true, y_pred), 2)),`: This calculates the Mean Absolute Error (MAE).\n",
    "    *   `mean_absolute_error(y_true, y_pred)`:  This function from `sklearn.metrics` computes the average absolute difference between the true values (`y_true`) and the predicted values (`y_pred`). MAE gives equal weight to all errors.\n",
    "    *   `round(..., 2)`: This rounds the result of `mean_absolute_error` to two decimal places, improving readability.\n",
    "    *   `float(...)`: Converts the rounded value to a floating-point number.  This ensures consistent data type in the dictionary.\n",
    "    *   `\"MAE\": ...`: This assigns the calculated and formatted MAE value to the key \"MAE\" in the dictionary.\n",
    "\n",
    "*   `\"RMSE\": float(round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)),`:  This calculates the Root Mean Squared Error (RMSE).\n",
    "    *   `mean_squared_error(y_true, y_pred)`: This function from `sklearn.metrics` computes the average squared difference between the true and predicted values.\n",
    "    *   `np.sqrt(...)`: Calculates the square root of the mean squared error to obtain the RMSE.\n",
    "    *   `round(..., 2)`: This rounds the result to two decimal places, improving readability.\n",
    "    *   `float(...)`: Converts the rounded value to a floating-point number.\n",
    "    *   `\"RMSE\": ...`: This assigns the calculated and formatted RMSE value to the key \"RMSE\" in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e0f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"MAE\": round(mean_absolute_error(y_true, y_pred), 2),\n",
    "        \"RMSE\": round(np.sqrt(mean_squared_error(y_true, y_pred)), 2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f77fc2",
   "metadata": {},
   "source": [
    "This function `forecast_metrics` calculates and returns common error metrics used to evaluate the accuracy of time series forecasts. It provides a concise way to assess how well your model's predictions align with the actual observed values.\n",
    "\n",
    "*   `def forecast_metrics(y_true, y_pred):`: This defines a function named `forecast_metrics` that takes two arguments:\n",
    "    *   `y_true`:  This represents the actual (observed) values of your time series. It's typically a NumPy array or Pandas Series.\n",
    "    *   `y_pred`: This represents the predicted values generated by your forecasting model. It should have the same length as `y_true`.\n",
    "\n",
    "*   `return { ... }`: The function returns a dictionary containing the calculated error metrics. Dictionaries are useful for storing key-value pairs, making it easy to access specific metrics by their names.\n",
    "\n",
    "*   `\"MAE\": mean_absolute_error(y_true, y_pred),`: This calculates the Mean Absolute Error (MAE).\n",
    "    *   `mean_absolute_error(y_true, y_pred)`:  This function from `sklearn.metrics` computes the average absolute difference between the true values (`y_true`) and the predicted values (`y_pred`). MAE gives equal weight to all errors.\n",
    "    *   `\"MAE\": ...`: This assigns the calculated MAE value to the key \"MAE\" in the dictionary.\n",
    "\n",
    "*   `\"RMSE\": mean_squared_error(y_true, y_pred, squared=False),`:  This calculates the Root Mean Squared Error (RMSE).\n",
    "    *   `mean_squared_error(y_true, y_pred, squared=False)`: This function from `sklearn.metrics` computes the square root of the average squared difference between the true and predicted values. The `squared=False` argument ensures that we get the RMSE directly (the square root), rather than the Mean Squared Error (MSE).  RMSE penalizes larger errors more heavily than MAE because of the squaring operation.\n",
    "    *   `\"RMSE\": ...`: This assigns the calculated RMSE value to the key \"RMSE\" in the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc6c27",
   "metadata": {},
   "source": [
    "# Exponential smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4c3d2",
   "metadata": {},
   "source": [
    "## Single ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd2a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ses_smoothing(series_df, alpha, horizon, value_col=\"series\"):\n",
    "    ses_model = SimpleExpSmoothing(series_df[value_col])\n",
    "    ses_fit = ses_model.fit(  smoothing_level=alpha, optimized=False)\n",
    "\n",
    "    forecast = ses_fit.forecast(horizon)\n",
    "    plt.figure()\n",
    "\n",
    "    # Original series\n",
    "    series_df[value_col].plot( label=\"Observed\", linewidth=2, )\n",
    "    # Smoothed (fitted) values\n",
    "    ses_fit.fittedvalues.plot( label=f\"Smoothed (α={alpha})\", linewidth=2 , color = \"red\"   )\n",
    "    # Forecast\n",
    "    forecast.plot( label=\"Forecast\", marker=\"o\", linestyle=\"--\", color=\"green\" )\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e82e08",
   "metadata": {},
   "source": [
    "This helper function `plot_ses_smoothing` visualizes the results of applying Simple Exponential Smoothing (SES) to a time series, including both the smoothed values and forecasts. It’s designed to help you understand how SES works and assess its performance on your data.\n",
    "\n",
    "\n",
    "*   `def plot_ses_smoothing(series_df, alpha, horizon, value_col=\"series\"):`: This defines a function named `plot_ses_smoothing` that takes four arguments:\n",
    "    *   `series_df`: A Pandas DataFrame containing your time series data. It's expected to have a column with the time series values.\n",
    "    *   `alpha`: The smoothing level for SES, controlling how much weight is given to recent observations.\n",
    "    *   `horizon`:  The number of periods into the future you want to forecast. This determines the length of the forecast horizon.\n",
    "    *   `value_col=\"series\"`: Specifies the name of the column in `series_df` that contains the time series values. It defaults to \"series\" but can be changed if your data uses a different column name.\n",
    "\n",
    "*   `ses_model = SimpleExpSmoothing(series_df[value_col])`: This creates an instance of the `SimpleExpSmoothing` class, initializing it with the time series data from the specified column in the DataFrame.\n",
    "\n",
    "*   `ses_fit = ses_model.fit(  smoothing_level=alpha, optimized=False)`: This fits (trains) the SES model to the data using the provided smoothing level (`alpha`). `optimized=False` prevents the model from automatically searching for the best alpha value; we're explicitly setting it.\n",
    "\n",
    "*   `forecast = ses_fit.forecast(horizon)`:  This generates a forecast for the specified `horizon` (number of periods into the future) using the fitted SES model.\n",
    "\n",
    "*   `plt.figure()`: This creates a new Matplotlib figure, which will contain the plot.\n",
    "\n",
    "*   `series_df[value_col].plot( label=\"Observed\", linewidth=2, )`:  This plots the original time series data as a line, with a width of 2. The `label=\"Observed\"` assigns a label to this line for use in the legend.\n",
    "\n",
    "*   `ses_fit.fittedvalues.plot( label=f\"Smoothed (α={alpha})\", linewidth=2 , color = \"red\"   )`: This plots the smoothed values generated by the SES model (the *in-sample fitted values*) as a line with a line width of 2 and red color. The `label` dynamically includes the value of `alpha` used for smoothing, making it clear which smoothing level was applied.  Using red helps visually distinguish the smoothed line from the original data.\n",
    "\n",
    "*   `forecast.plot( label=\"Forecast\", marker=\"o\", linestyle=\"--\", color=\"green\" )`: This plots the forecasted values as a dashed line (`linestyle=\"--\"`) with circular markers (`marker=\"o\"`), and a green color. The `label=\"Forecast\"` assigns a label for the legend.  The green color differentiates the forecast from both the observed data and the smoothed curve.\n",
    "\n",
    "*   `plt.legend()`:  This displays the legend on the plot, showing the labels assigned to each line (Observed, Smoothed, Forecast). The different colors will be represented in the legend as well.\n",
    "\n",
    "*   `plt.show()`: This displays the generated plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faef5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 12\n",
    "ALPHAS = [0.2, 0.5, 0.9]\n",
    "\n",
    "series_df = pd.read_csv(\n",
    "    CFG.data_folder + \"exp1.csv\",\n",
    "    header=None,names=[\"series\"],\n",
    ")\n",
    "\n",
    "for alpha in ALPHAS:\n",
    "    plot_ses_smoothing(series_df, alpha=alpha, horizon=HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee60a33",
   "metadata": {},
   "source": [
    "This code demonstrates the application of Simple Exponential Smoothing (SES) with different smoothing levels (`alpha`). \n",
    "\n",
    "*   `df = pd.read_csv(CFG.data_folder + 'exp1.csv', header = None); df.columns = ['series']`: This line reads data from a CSV file named \"exp1.csv\" located in the directory specified by `CFG.data_folder`.\n",
    "    *   `pd.read_csv(...)`:  This is the Pandas function for reading data from a comma-separated value (CSV) file.\n",
    "    *   `header = None`: This argument tells `read_csv` that the CSV file does *not* have a header row containing column names.\n",
    "    *   `df.columns = ['series']`:  After reading the data, this line assigns the name \"series\" to the single column in the DataFrame.\n",
    "\n",
    "*   `# synthetic data demonstration`: This is just a comment indicating that the following code demonstrates SES on some example (likely synthetic) time series data.\n",
    "\n",
    "*   `for alpha_sm in [0.2 , 0.5, 0.9]:`:  This starts a loop that iterates through three different values for the smoothing level (`alpha_sm`): 0.2, 0.5, and 0.9. The smoothing level controls how much weight is given to recent observations versus past observations in the SES model.\n",
    "\n",
    "*   `df.plot.line()`: This plots the original time series data as a line plot using Pandas' built-in plotting functionality.  This provides a visual baseline for comparison with the smoothed and forecasted values.\n",
    "\n",
    "*   `fit1 = SimpleExpSmoothing(df).fit(smoothing_level = alpha_sm  ,optimized=False)`: This is where the SES model is fitted to the data.\n",
    "    *   `SimpleExpSmoothing(df)`: Creates an instance of the `SimpleExpSmoothing` class from the `statsmodels` library, initializing it with your time series data (`df`).\n",
    "    *   `.fit(smoothing_level = alpha_sm  ,optimized=False)`: This fits (trains) the SES model to the data.\n",
    "        *   `smoothing_level = alpha_sm`: Sets the smoothing level for this particular iteration of the loop.\n",
    "        *   `optimized=False`:  This is important! It tells `SimpleExpSmoothing` *not* to automatically find the optimal smoothing level using optimization techniques. We are explicitly setting it with `alpha_sm`. If set to `True`, the model would search for the best alpha value, which isn't what we want in this demonstration.\n",
    "\n",
    "*   `fcast1 = fit1.forecast(12).rename('alpha = ' + str(alpha_sm))`: This generates a forecast using the fitted SES model.\n",
    "    *   `fit1.forecast(12)`:  This uses the trained `fit1` model to predict the next 12 values in the time series.\n",
    "    *   `.rename('alpha = ' + str(alpha_sm))`: This renames the forecast series to include the value of `alpha_sm` used for that particular forecast, making it easier to distinguish between forecasts generated with different smoothing levels on the plot's legend.\n",
    "\n",
    "*   `fcast1.plot(marker='o', color='red', legend=True)`:  This plots the forecasted values as a line with circular markers ('o'), colored red, and includes a legend entry.\n",
    "\n",
    "*   `fit1.fittedvalues.plot(  color='red')`: This plots the *in-sample fitted values*. These are the smoothed values that the model calculated for the data it was trained on (the original time series). Plotting these helps visualize how well the SES model fits the historical data. They're also colored red to match the forecast line.\n",
    "\n",
    "*   `plt.show()`: This displays the plot, showing the original time series, the fitted values, and the forecasted values for a specific `alpha_sm`.  The loop then repeats with the next value of `alpha_sm`, creating a new plot each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da9105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.5\n",
    "HORIZON = 12\n",
    "\n",
    "passengers_df = pd.read_csv( CFG.data_folder + \"passengers.csv\", usecols=[\"passengers\"])\n",
    "\n",
    "plot_ses_smoothing( passengers_df, alpha=ALPHA, horizon=HORIZON, value_col=\"passengers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcdcfbe",
   "metadata": {},
   "source": [
    "This code applies Simple Exponential Smoothing (SES) to a time series dataset of passenger numbers and visualizes the results using the `plot_ses_smoothing` function we've discussed. Let’s break it down:\n",
    "\n",
    "*   `ALPHA = 0.5`: This line defines a constant variable named `ALPHA` and sets its value to 0.5.  This represents the smoothing level that will be used in the SES model. A value of 0.5 means that each new observation is given half the weight of the previous forecast, and the previous forecast receives the other half.\n",
    "\n",
    "*   `HORIZON = 12`: This line defines a constant variable named `HORIZON` and sets its value to 12.  This represents the number of time periods into the future for which we want to generate forecasts. In this context, it likely means forecasting passenger numbers for the next 12 months (or whatever the time unit is in your dataset).\n",
    "\n",
    "*   `passengers_df = pd.read_csv( CFG.data_folder + \"passengers.csv\", usecols=[\"passengers\"])`: This line reads data from a CSV file named \"passengers.csv\" located in the directory specified by `CFG.data_folder`.\n",
    "    *   `pd.read_csv(...)`:  This is the Pandas function for reading data from a comma-separated value (CSV) file.\n",
    "    *   `usecols=[\"passengers\"]`: This argument tells `read_csv` to only read the column named \"passengers\" from the CSV file, creating a DataFrame with just that single column.\n",
    "\n",
    "*   `plot_ses_smoothing( passengers_df, alpha=ALPHA, horizon=HORIZON, value_col=\"passengers\")`:  This line calls the `plot_ses_smoothing` function to perform SES and generate a visualization.\n",
    "    *   `passengers_df`: This passes the DataFrame containing the passenger data as the first argument (`series_df`).\n",
    "    *   `alpha=ALPHA`: This sets the smoothing level for the SES model to the value stored in the `ALPHA` variable (0.5).\n",
    "    *   `horizon=HORIZON`:  This sets the forecast horizon to the value stored in the `HORIZON` variable (12).\n",
    "    *   `value_col=\"passengers\"`: This specifies that the column named \"passengers\" in the DataFrame contains the time series values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ab0a5",
   "metadata": {},
   "source": [
    "## Double Exponential Smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b5d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function - similar to plot_ses_smoothing\n",
    "\n",
    "def plot_holt_smoothing( series_df, alpha, beta, horizon,  value_col):\n",
    "    holt_model = Holt(series_df[value_col])\n",
    "    holt_fit = holt_model.fit(\n",
    "        smoothing_level=alpha, smoothing_slope=beta, optimized=False,\n",
    "    )\n",
    "\n",
    "    forecast = holt_fit.forecast(horizon)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    series_df[value_col].plot( label=\"Observed\", linewidth=2    )\n",
    "\n",
    "    holt_fit.fittedvalues.plot( label=f\"Smoothed (α={alpha}, β={beta})\",linewidth=2, color = \"red\"     )\n",
    "\n",
    "    forecast.plot( label=\"Forecast\",  marker=\"o\", linestyle=\"--\", color=\"green\" )\n",
    "\n",
    "\n",
    "    plt.title(\"Holt’s Linear Trend Method\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb82f1",
   "metadata": {},
   "source": [
    "This code defines a function `plot_holt_smoothing` that visualizes the results of applying Holt's linear trend method to a time series dataset. It’s very similar in structure to the `plot_ses_smoothing` function we previously discussed, but it implements a more sophisticated smoothing technique that accounts for trends in the data.\n",
    "\n",
    "\n",
    "*   `def plot_holt_smoothing( series_df, alpha, beta, horizon,  value_col):`: This defines a function named `plot_holt_smoothing` that takes five arguments:\n",
    "    *   `series_df`: A Pandas DataFrame containing your time series data. It's expected to have a column with the time series values.\n",
    "    *   `alpha`: The smoothing level for the level component of Holt’s method, controlling how much weight is given to recent observations when updating the current level.\n",
    "    *   `beta`: The smoothing level for the trend component of Holt’s method, controlling how much weight is given to recent changes in the series when updating the trend.\n",
    "    *   `horizon`:  The number of time periods into the future you want to forecast.\n",
    "    *   `value_col`: Specifies the name of the column in `series_df` that contains the time series values.\n",
    "\n",
    "*   `holt_model = Holt(series_df[value_col])`: This creates an instance of the `Holt` class from the `statsmodels` library, initializing it with the time series data from the specified column in the DataFrame.  The `Holt` method is designed for time series that exhibit a trend (increasing or decreasing pattern).\n",
    "\n",
    "*   `holt_fit = holt_model.fit( smoothing_level=alpha, smoothing_slope=beta, optimized=False,)`: This fits (trains) the Holt’s model to the data using the provided smoothing levels for both the level (`alpha`) and trend (`beta`) components. `optimized=False` prevents automatic optimization of these parameters; we're explicitly setting them.\n",
    "\n",
    "*   `forecast = holt_fit.forecast(horizon)`:  This generates a forecast for the specified `horizon` (number of periods into the future) using the fitted Holt’s model.\n",
    "\n",
    "*   `plt.figure()`: This creates a new Matplotlib figure, which will contain the plot.\n",
    "\n",
    "*   `series_df[value_col].plot( label=\"Observed\", linewidth=2 )`:  This plots the original time series data as a line with a width of 2. The `label=\"Observed\"` assigns a label to this line for use in the legend.\n",
    "\n",
    "*   `holt_fit.fittedvalues.plot( label=f\"Smoothed (α={alpha}, β={beta})\",linewidth=2, color = \"red\" )`: This plots the smoothed values generated by Holt’s model (the *in-sample fitted values*) as a line with a line width of 2 and a **red** color. The `label` dynamically includes the values of both `alpha` and `beta`, making it clear which smoothing levels were used.\n",
    "\n",
    "*   `forecast.plot( label=\"Forecast\",  marker=\"o\", linestyle=\"--\", color=\"green\" )`: This plots the forecasted values as a dashed line (`linestyle=\"--\"`) with circular markers (`marker=\"o\"`), and a **green** color. The `label=\"Forecast\"` assigns a label for the legend.\n",
    "\n",
    "*   `plt.title(\"Holt’s Linear Trend Method\")`:  This sets the title of the plot to \"Holt’s Linear Trend Method\", indicating which forecasting method is being visualized.\n",
    "\n",
    "*   `plt.legend()`:  This displays the legend on the plot, showing the labels assigned to each line (Observed, Smoothed, Forecast). The different colors will be represented in the legend as well.\n",
    "\n",
    "*   `plt.show()`: This displays the generated plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae8df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEVEL_ALPHA = 0.5\n",
    "TREND_BETA = 0.5\n",
    "HORIZON = 12\n",
    "\n",
    "plot_holt_smoothing(\n",
    "    passengers_df, alpha=LEVEL_ALPHA,  beta=TREND_BETA, horizon=HORIZON,  value_col=\"passengers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e34c006",
   "metadata": {},
   "source": [
    "This code snippet applies Holt's linear trend method to the passenger data and visualizes the results using the `plot_holt_smoothing` function. \n",
    "\n",
    "*   `LEVEL_ALPHA = 0.5`: This line defines a constant variable named `LEVEL_ALPHA` and sets its value to 0.5.  This represents the smoothing level for the *level* component of Holt's method. It controls how much weight is given to recent observations when updating the current level of the series.\n",
    "\n",
    "*   `TREND_BETA = 0.5`: This line defines a constant variable named `TREND_BETA` and sets its value to 0.5.  This represents the smoothing level for the *trend* component of Holt's method. It controls how much weight is given to recent changes in the series when updating the trend.\n",
    "\n",
    "*   `HORIZON = 12`: This line defines a constant variable named `HORIZON` and sets its value to 12.  This represents the number of time periods into the future for which we want to generate forecasts. In this context, it likely means forecasting passenger numbers for the next 12 months (or whatever the time unit is in your dataset).\n",
    "\n",
    "*   `plot_holt_smoothing( passengers_df, alpha=LEVEL_ALPHA,  beta=TREND_BETA, horizon=HORIZON,  value_col=\"passengers\")`: This line calls the `plot_holt_smoothing` function to perform Holt's smoothing and generate a visualization.\n",
    "    *   `passengers_df`: This passes the DataFrame containing the passenger data as the first argument (`series_df`).\n",
    "    *   `alpha=LEVEL_ALPHA`: This sets the smoothing level for the level component of Holt’s method to the value stored in the `LEVEL_ALPHA` variable (0.5).\n",
    "    *   `beta=TREND_BETA`:  This sets the smoothing level for the trend component of Holt’s method to the value stored in the `TREND_BETA` variable (0.5).\n",
    "    *   `horizon=HORIZON`: This sets the forecast horizon to the value stored in the `HORIZON` variable (12).\n",
    "    *   `value_col=\"passengers\"`: This specifies that the column named \"passengers\" in the DataFrame contains the time series values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f07391",
   "metadata": {},
   "source": [
    "## Triple exponential smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fc443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_holt_winters_additive( series_df, alpha, seasonal_period, horizon, value_col, y_lim=None):\n",
    "    hw_model = ExponentialSmoothing(\n",
    "        series_df[value_col],\n",
    "        trend=\"add\", seasonal=\"mul\", seasonal_periods=seasonal_period,\n",
    "    )\n",
    "\n",
    "    hw_fit = hw_model.fit( smoothing_level=alpha, optimized= True,)\n",
    "\n",
    "    forecast = hw_fit.forecast(horizon)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    series_df[value_col].plot( label=\"Observed\", linewidth=2    )\n",
    "\n",
    "    hw_fit.fittedvalues.plot( label=\"Smoothed\", linewidth=2,color = \"red\")\n",
    "\n",
    "    forecast.plot(label=\"Forecast\", marker=\"o\", linestyle=\"--\")\n",
    "\n",
    "    plt.title(\"Holt-Winters Additive Smoothing\")\n",
    "    plt.legend()\n",
    "\n",
    "    if y_lim is not None:\n",
    "        plt.ylim(y_lim)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266cce68",
   "metadata": {},
   "source": [
    "This code defines a function `plot_holt_winters_additive` that visualizes the results of applying Holt-Winters' additive smoothing method to a time series dataset. This method is particularly useful for data exhibiting both trend and seasonality.\n",
    "\n",
    "*   `def plot_holt_winters_additive( series_df, alpha, seasonal_period, horizon, value_col, y_lim=None):`:  This defines a function named `plot_holt_winters_additive` that takes six arguments:\n",
    "    *   `series_df`: A Pandas DataFrame containing your time series data. It's expected to have a column with the time series values.\n",
    "    *   `alpha`: The smoothing level for the level component of Holt-Winters’ method, controlling how much weight is given to recent observations when updating the current level.\n",
    "    *   `seasonal_period`:  The length of the seasonal cycle in your data (e.g., 12 for monthly data with yearly seasonality).\n",
    "    *   `horizon`: The number of time periods into the future you want to forecast.\n",
    "    *   `value_col`: Specifies the name of the column in `series_df` that contains the time series values.\n",
    "    *   `y_lim=None`: An optional argument allowing you to set the y-axis limits for the plot. If not provided (i.e., remains `None`), the plot will automatically determine appropriate limits.\n",
    "\n",
    "*   `hw_model = ExponentialSmoothing( series_df[value_col], trend=\"add\", seasonal=\"mul\", seasonal_periods=seasonal_period,)`: This creates an instance of the `ExponentialSmoothing` class from the `statsmodels` library, initializing it with the time series data and specifying the model parameters.\n",
    "    *   `series_df[value_col]`:  Provides the time series data to the model.\n",
    "    *   `trend=\"add\"`: Specifies that an additive trend component should be included in the model. This means the trend is added to the level of the series.\n",
    "    *   `seasonal=\"mul\"`: Specifies a multiplicative seasonal component. This means the seasonality is multiplied by the level of the series.  (Additive seasonality could also be used, but multiplicative is often preferred when the magnitude of the seasonal fluctuations changes with the level of the series).\n",
    "    *   `seasonal_periods=seasonal_period`: Sets the length of the seasonal cycle.\n",
    "\n",
    "*   `hw_fit = hw_model.fit( smoothing_level=alpha, optimized= True,)`: This fits (trains) the Holt-Winters model to the data using the provided smoothing level for the level component (`alpha`).\n",
    "    *   `optimized=True`:  This is important! It tells `ExponentialSmoothing` to automatically find the optimal values for all smoothing parameters (level, trend, and seasonality) using optimization techniques. This often leads to better forecasting accuracy than manually setting these parameters.\n",
    "\n",
    "*   `forecast = hw_fit.forecast(horizon)`: This generates a forecast for the specified `horizon` (number of periods into the future) using the fitted Holt-Winters model.\n",
    "\n",
    "*   `plt.figure()`: This creates a new Matplotlib figure, which will contain the plot.\n",
    "\n",
    "*   `series_df[value_col].plot( label=\"Observed\", linewidth=2 )`:  This plots the original time series data as a line with a default black color and a line width of 2. The `label=\"Observed\"` assigns a label to this line for use in the legend.\n",
    "\n",
    "*   `hw_fit.fittedvalues.plot( label=\"Smoothed\", linewidth=2,color = \"red\")`: This plots the smoothed values generated by Holt-Winters’ model (the *in-sample fitted values*) as a line with a line width of 2 and a **red** color. The `label` is set to “Smoothed”.\n",
    "\n",
    "*   `forecast.plot(label=\"Forecast\", marker=\"o\", linestyle=\"--\")`: This plots the forecasted values as a dashed line (`linestyle=\"--\"`) with circular markers (`marker=\"o\"`). The `label=\"Forecast\"` assigns a label for the legend.\n",
    "\n",
    "*   `plt.title(\"Holt-Winters Additive Smoothing\")`:  This sets the title of the plot to \"Holt-Winters Additive Smoothing\", indicating which forecasting method is being visualized.\n",
    "\n",
    "*   `plt.legend()`: This displays the legend on the plot, showing the labels assigned to each line (Observed, Smoothed, Forecast).\n",
    "\n",
    "*   `if y_lim is not None: plt.ylim(y_lim)`:  This conditionally sets the y-axis limits of the plot if a `y_lim` value was provided as an argument to the function. This can be useful for comparing plots with different scales.\n",
    "\n",
    "*   `plt.show()`: This displays the generated plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72604f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEVEL_ALPHA = 0.5\n",
    "SEASONAL_PERIOD = 12\n",
    "HORIZON = 12\n",
    "Y_LIM = (0, 800)\n",
    "\n",
    "plot_holt_winters_additive(\n",
    "    passengers_df,\n",
    "    alpha=LEVEL_ALPHA,\n",
    "    seasonal_period=SEASONAL_PERIOD,\n",
    "    horizon=HORIZON,\n",
    "    value_col=\"passengers\",\n",
    "    y_lim=Y_LIM,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679b6bc0",
   "metadata": {},
   "source": [
    "This code snippet applies Holt-Winters' exponential smoothing to the \"passengers\" dataset, which is suitable for time series data with both trend and seasonality. It forecasts 12 periods into the future and visualizes the smoothed data (fitted values) and the forecast. \n",
    "\n",
    "**1. Data Loading & Initial Plotting:**\n",
    "\n",
    "*   `alpha = 0.5`: Sets a variable `alpha`, which is used as the smoothing level in this case, but note that Holt-Winters automatically optimizes all smoothing parameters if not explicitly set.\n",
    "*   `df.plot.line()`: Creates a line plot of the original time series data, showing the raw passenger numbers over time.\n",
    "\n",
    "**2. Holt-Winters Exponential Smoothing & Fitting:**\n",
    "\n",
    "*   `fit1 = ExponentialSmoothing(df, seasonal_periods=12, trend='add', seasonal='add')`:\n",
    "    *   `ExponentialSmoothing(df, ...)`: Creates an instance of the `ExponentialSmoothing` class from `statsmodels`, initializing it with the time series data (`df`). This is the core Holt-Winters implementation.\n",
    "        *   `seasonal_periods=12`: Specifies that the seasonality has a period of 12 (e.g., monthly data with yearly seasonality).  This tells the model to look for repeating patterns every 12 periods.\n",
    "        *   `trend='add'`: Indicates that the trend component is additive. This means the trend is added to the seasonal and level components. Use `'mul'` for a multiplicative trend (where the trend multiplies the other components).\n",
    "        *   `seasonal='add'`:  Indicates that the seasonal component is additive. This means the seasonality is added to the level and trend components. Use `'mul'` for a multiplicative seasonal component.\n",
    "\n",
    "*   `fit1 = fit1.fit(smoothing_level=0.5)`: Fits the Holt-Winters model to the data.\n",
    "    * `smoothing_level=0.5`: Sets the initial smoothing level (alpha) to 0.5.  However, because no other smoothing parameters are explicitly set, statsmodels will *optimize* all three smoothing parameters (alpha, beta for trend, and gamma for seasonality) to find the best fit to the data.\n",
    "\n",
    "**3. Plotting Fitted Values:**\n",
    "\n",
    "*   `fit1.fittedvalues.plot(color='red')`: Plots the fitted values (the smoothed time series) generated by the Holt-Winters model as a red line. These represent the estimated values of the time series based on the trend and seasonal components.\n",
    "\n",
    "**4. Plotting Forecasts:**\n",
    "\n",
    "*   `fit1.forecast(12).rename(\"Holt-Winters smoothing\").plot(color='red', legend=True)`:\n",
    "    *   `fit1.forecast(12)`: Uses the fitted model (`fit1`) to generate forecasts for the next 12 time steps (periods).\n",
    "    *   `.rename(...)`: Renames the forecast series in the DataFrame to \"Holt-Winters smoothing\", making it easier to identify on the plot.\n",
    "    *   `.plot(color='red', legend=True)`: Plots the forecasted values as a red line and adds them to the legend.\n",
    "\n",
    "**5. Setting Y-axis Limits & Displaying Plot:**\n",
    "\n",
    "*   `plt.ylim(0, 800)`: Sets the limits of the y-axis (vertical axis) of the plot from 0 to 800. This ensures that the entire time series and forecast are visible within the plot's bounds.\n",
    "*   `plt.show()`: Displays the plot, showing the original time series, the fitted values, and the forecasts generated by Holt-Winters smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f512cfdc",
   "metadata": {},
   "source": [
    "# Application: anomaly detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a598e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambient_df = pd.read_csv(CFG.data_folder + 'ambient_temperature_system_failure.csv')\n",
    "ambient_df['timestamp'] = pd.to_datetime(ambient_df['timestamp'])\n",
    "ambient_df.set_index('timestamp', inplace=True)\n",
    "\n",
    "ambient_df['value'].plot(xlabel = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4afb429",
   "metadata": {},
   "source": [
    "This code snippet loads time series data from a CSV file, prepares it for analysis by converting the timestamp column to datetime objects and setting it as the index, and then plots the time series.  \n",
    "\n",
    "*   `series = pd.read_csv(CFG.data_folder + 'ambient_temperature_system_failure.csv')`: This line reads data from a CSV file named \"ambient\\_temperature\\_system\\_failure.csv\" located in the directory specified by `CFG.data_folder`.  The `pd.read_csv()` function is used to import the data into a Pandas DataFrame called `series`.\n",
    "\n",
    "*   `series['timestamp'] = pd.to_datetime(series['timestamp'])`: This line converts the 'timestamp' column in the DataFrame to datetime objects.\n",
    "    *   `series['timestamp']`: Selects the 'timestamp' column from the DataFrame.\n",
    "    *   `pd.to_datetime(...)`:  This Pandas function parses strings representing dates and times into Python datetime objects, which are essential for time series analysis.\n",
    "\n",
    "*   `series.set_index('timestamp', inplace=True)`: This line sets the 'timestamp' column as the index of the DataFrame.\n",
    "    *   `series.set_index('timestamp')`:  This method changes the DataFrame so that the values in the 'timestamp' column are used as the row labels (the index).\n",
    "    *   `inplace=True`: This argument modifies the DataFrame directly, rather than creating a new copy.\n",
    "\n",
    "*   `series['value'].plot(xlabel = \"\")`: This line plots the time series data.\n",
    "    *   `series['value']`: Selects the 'value' column from the DataFrame (presumably containing the temperature readings).\n",
    "    *   `.plot()`:  This Pandas method creates a line plot of the selected data.\n",
    "    *   `xlabel = \"\"`: This sets the label for the x-axis to an empty string, effectively removing it from the plot. Since the x-axis represents time and is already indicated by the datetime index, this can make the plot cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e87e27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rolling_zscore(df, value_col, window):\n",
    "    rolling_mean = df[value_col].rolling(window).mean()\n",
    "    rolling_std = df[value_col].rolling(window).std()\n",
    "\n",
    "    zscore = (df[value_col] - rolling_mean) / rolling_std\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"zscore\": zscore.abs(),\n",
    "        },\n",
    "        index=df.index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6407bb",
   "metadata": {},
   "source": [
    "This function `compute_rolling_zscore` calculates the rolling Z-score for a given time series column within a DataFrame. The rolling Z-score is a useful technique for identifying anomalies or outliers in time series data because it measures how many standard deviations away from the mean each data point is, considering only a recent window of observations.\n",
    "\n",
    "*   `def compute_rolling_zscore(df, value_col, window):`: This defines a function named `compute_rolling_zscore` that takes three arguments:\n",
    "    *   `df`: The Pandas DataFrame containing your time series data.\n",
    "    *   `value_col`:  The name of the column in the DataFrame that contains the time series values you want to analyze.\n",
    "    *   `window`: The size of the rolling window (i.e., the number of previous data points) used to calculate the mean and standard deviation.\n",
    "\n",
    "*   `rolling_mean = df[value_col].rolling(window).mean()`: This calculates the rolling mean of the time series values.\n",
    "    *   `df[value_col]`: Selects the specified column from the DataFrame.\n",
    "    *   `.rolling(window)`: Creates a rolling window object that moves across the time series, considering `window` number of consecutive data points at each step.\n",
    "    *   `.mean()`: Calculates the mean (average) value within each rolling window.\n",
    "\n",
    "*   `rolling_std = df[value_col].rolling(window).std()`: This calculates the rolling standard deviation of the time series values, using the same rolling window as above.\n",
    "    *   `.std()`:  Calculates the standard deviation within each rolling window. The standard deviation measures the spread or dispersion of the data around the mean.\n",
    "\n",
    "*   `zscore = (df[value_col] - rolling_mean) / rolling_std`: This calculates the Z-score for each data point in the time series.\n",
    "    *   `(df[value_col] - rolling_mean)`:  Calculates the difference between each original value and its corresponding rolling mean. This represents how much each value deviates from the average of its recent neighbors.\n",
    "    *   `/ rolling_std`: Divides the deviation by the rolling standard deviation. This normalizes the deviation, expressing it in terms of standard deviations.\n",
    "\n",
    "*   `return pd.DataFrame( { \"zscore\": zscore.abs(), }, index=df.index,)`:  This returns a new Pandas DataFrame containing the calculated Z-scores.\n",
    "    *   `{\"zscore\": zscore.abs()}`: Creates a dictionary where the key is \"zscore\" and the value is the absolute value of the calculated Z-scores (`zscore.abs()`). Taking the absolute value ensures that both positive and negative deviations from the mean are considered as potential anomalies.\n",
    "    *   `index=df.index`: Sets the index of the new DataFrame to be the same as the original DataFrame, ensuring that the Z-scores are aligned with their corresponding timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c78b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_zscore_with_anomalies( zscore_df, value_col=\"zscore\",  threshold=3.0):\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot full z-score series\n",
    "    zscore_df[value_col].plot(\n",
    "        label=\"Z-score\", linewidth=2)\n",
    "\n",
    "    # Highlight anomalies\n",
    "    anomalies = zscore_df[zscore_df[value_col] > threshold]\n",
    "\n",
    "    plt.scatter(\n",
    "        anomalies.index, anomalies[value_col],\n",
    "        color=\"red\", label=f\"Anomalies (>{threshold})\",\n",
    "        zorder=3,)\n",
    "\n",
    "    # plt.axhline( threshold,\n",
    "    #     color=\"red\",  linestyle=\"--\", alpha=0.7,\n",
    "    # )\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056e1908",
   "metadata": {},
   "source": [
    "This function `plot_zscore_with_anomalies` visualizes a time series of Z-scores and highlights potential anomalies based on a specified threshold. It’s designed to help you identify unusual data points in your time series after calculating the rolling Z-score.\n",
    "\n",
    "*   `def plot_zscore_with_anomalies( zscore_df, value_col=\"zscore\",  threshold=3.0):`: This defines a function named `plot_zscore_with_anomalies` that takes three arguments:\n",
    "    *   `zscore_df`: A Pandas DataFrame containing the Z-scores calculated using a function like `compute_rolling_zscore`.\n",
    "    *   `value_col=\"zscore\"`: The name of the column in the DataFrame that contains the Z-score values. It defaults to \"zscore\".\n",
    "    *   `threshold=3.0`: A numerical value representing the threshold for identifying anomalies. Data points with a Z-score (absolute value) greater than this threshold are considered anomalies.\n",
    "\n",
    "*   `plt.figure()`: This creates a new Matplotlib figure, which will contain the plot.\n",
    "\n",
    "*   `zscore_df[value_col].plot( label=\"Z-score\", linewidth=2)`: This plots the entire Z-score time series as a line graph.\n",
    "    *   `zscore_df[value_col]`: Selects the column containing the Z-scores from the DataFrame.\n",
    "    *   `.plot()`: Creates a line plot of the Z-score values.\n",
    "    *   `label=\"Z-score\"`: Assigns a label to the line for use in the legend.\n",
    "    *   `linewidth=2`: Sets the width of the line to 2 points.\n",
    "\n",
    "*   `anomalies = zscore_df[zscore_df[value_col] > threshold]`: This identifies the anomalies based on the specified threshold.\n",
    "    *   `zscore_df[zscore_df[value_col] > threshold]`:  This uses boolean indexing to select rows from the `zscore_df` where the value in the `value_col` (Z-score) is greater than the `threshold`. These are considered anomalies.\n",
    "\n",
    "*   `plt.scatter( anomalies.index, anomalies[value_col], color=\"red\", label=f\"Anomalies (>{threshold})\", zorder=3,)`: This plots the identified anomalies as red scatter points on the graph.\n",
    "    *   `anomalies.index`:  Provides the timestamps (or index values) of the anomalies for the x-axis.\n",
    "    *   `anomalies[value_col]`: Provides the Z-score values of the anomalies for the y-axis.\n",
    "    *   `color=\"red\"`: Sets the color of the scatter points to red.\n",
    "    *   `label=f\"Anomalies (>{threshold})\"`: Assigns a label to the scatter points, indicating that they represent anomalies with Z-scores greater than the threshold. The `f` before the string allows you to embed the value of the `threshold` variable directly into the label.\n",
    "    *   `zorder=3`: Sets the z-order of the scatter points to 3, ensuring that they are drawn on top of the line plot (which has a default z-order of 0).\n",
    "\n",
    "*   `plt.legend()`: This displays the legend on the plot, showing the labels for the Z-score line and the anomaly scatter points.\n",
    "\n",
    "*   `plt.show()`: This displays the generated plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb5bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 25\n",
    "ZSCORE_THRESHOLD = 3.0\n",
    "\n",
    "zscore_df = compute_rolling_zscore(\n",
    "    ambient_df,\n",
    "    value_col=\"value\",\n",
    "    window=WINDOW_SIZE,\n",
    ")\n",
    "\n",
    "plot_zscore_with_anomalies(\n",
    "    zscore_df,\n",
    "    threshold=ZSCORE_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80c9e7a",
   "metadata": {},
   "source": [
    "This code snippet calculates the rolling Z-scores for a time series dataset and then visualizes those scores along with any identified anomalies. \n",
    "*   `WINDOW_SIZE = 25`: This line defines a constant variable named `WINDOW_SIZE` and sets its value to 25.  This represents the size of the rolling window used when calculating the Z-scores – meaning the mean and standard deviation are calculated using the previous 25 data points for each point in the time series.\n",
    "\n",
    "*   `ZSCORE_THRESHOLD = 3.0`: This line defines a constant variable named `ZSCORE_THRESHOLD` and sets its value to 3.0.  This represents the threshold used to identify anomalies. Any Z-score (absolute value) greater than 3.0 will be considered an anomaly.\n",
    "\n",
    "*   `zscore_df = compute_rolling_zscore( ambient_df, value_col=\"value\", window=WINDOW_SIZE,)`: This line calls the `compute_rolling_zscore` function to calculate the rolling Z-scores for your time series data.\n",
    "    *   `ambient_df`:  This is assumed to be a Pandas DataFrame containing your time series data (likely loaded earlier in your script). It’s expected to have a column named \"value\" containing the temperature readings.\n",
    "    *   `value_col=\"value\"`: This specifies that the column named \"value\" contains the time series values.\n",
    "    *   `window=WINDOW_SIZE`:  This sets the size of the rolling window to the value stored in the `WINDOW_SIZE` variable (25). The function returns a DataFrame containing the calculated Z-scores, which is assigned to the variable `zscore_df`.\n",
    "\n",
    "*   `plot_zscore_with_anomalies( zscore_df, threshold=ZSCORE_THRESHOLD)`: This line calls the `plot_zscore_with_anomalies` function to visualize the calculated Z-scores and highlight any anomalies.\n",
    "    *   `zscore_df`:  This passes the DataFrame containing the Z-scores (calculated in the previous step) as input.\n",
    "    *   `threshold=ZSCORE_THRESHOLD`: This sets the anomaly threshold to the value stored in the `ZSCORE_THRESHOLD` variable (3.0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268a417",
   "metadata": {},
   "source": [
    "# Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fff039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CFG.data_folder + 'us_energy.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace = True)\n",
    "df.plot(xlabel=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661acded",
   "metadata": {},
   "source": [
    "This load the CSV file containing US energy data, converts the 'date' column to datetime objects, sets the 'date' column as the DataFrame index, and then plots the time series data. \n",
    "\n",
    "**1. Loading the Data:**\n",
    "\n",
    "*   `df = pd.read_csv(CFG.data_folder + 'us_energy.csv')`:\n",
    "    *   `pd.read_csv(...)`: Reads a CSV file named \"us_energy.csv\" into a Pandas DataFrame called `df`.\n",
    "    *   `CFG.data_folder`: Assumes that there's a configuration object (likely defined elsewhere in the code) named `CFG`, which has an attribute `data_folder` containing the path to the directory where the data file is located.\n",
    "\n",
    "**2. Converting Date Column:**\n",
    "\n",
    "*   `df['date'] = pd.to_datetime(df['date'])`:\n",
    "    *   `df['date']`: Selects the column named 'date' from the DataFrame `df`. It assumes this column contains date information as strings or in a format Pandas can recognize.\n",
    "    *   `pd.to_datetime(...)`: Converts the values in the 'date' column to datetime objects using Pandas' `to_datetime()` function. This is essential for time series analysis, allowing you to perform operations like indexing by date/time and calculating time differences. The resulting datetime objects are assigned back to the 'date' column of the DataFrame.\n",
    "\n",
    "**3. Setting Date as Index:**\n",
    "\n",
    "*   `df.set_index('date', inplace = True)`:\n",
    "    *   `df.set_index('date')`: Sets the 'date' column as the index of the DataFrame `df`. This is a common practice in time series analysis, as it allows you to easily access data by date and perform time-based operations.\n",
    "    *   `inplace = True`: Modifies the DataFrame `df` directly without creating a new copy.\n",
    "\n",
    "**4. Plotting the Time Series:**\n",
    "\n",
    "*   `df.plot(xlabel=\"\")`: Creates a line plot of the time series data.  Since 'date' is now the index, Pandas automatically uses it as the x-axis.\n",
    "    *   `xlabel=\"\"`: Sets the label for the x-axis to an empty string, effectively removing the x-axis label from the plot. This might be done if the date information on the x-axis is already clear or if a custom label will be added later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52569a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(df[\"value\"],period =12, model = 'multiplicative')\n",
    "figure = decomposition.plot()\n",
    "for ax in figure.get_axes():\n",
    "    ax.set_title(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c8f929",
   "metadata": {},
   "source": [
    "This code performs a time series decomposition using the `seasonal_decompose` function from the `statsmodels` library and then visualizes the decomposed components (trend, seasonality, and residual).\n",
    "\n",
    "*   `decomposition = seasonal_decompose(df[\"value\"],period =12, model = 'multiplicative')`: This line performs the time series decomposition.\n",
    "    *   `seasonal_decompose(...)`:  This function from `statsmodels.tsa.seasonal` decomposes a time series into its constituent components: trend, seasonality, and residual (random noise).\n",
    "    *   `df[\"value\"]`: Specifies the time series data to be decomposed. It assumes your DataFrame (`df`) has a column named \"value\" containing the time series values.\n",
    "    *   `period = 12`:  This sets the length of the seasonal cycle. A value of 12 suggests monthly seasonality (like yearly patterns repeating every 12 months). This is crucial for accurately identifying and separating the seasonal component.\n",
    "    *   `model = 'multiplicative'`: This specifies the type of decomposition model to use. In a multiplicative model, the time series is assumed to be composed of trend * seasonality * residual.  This is appropriate when the magnitude of the seasonal fluctuations changes proportionally with the level of the series (e.g., larger seasonal swings during periods of higher overall values). An alternative would be `model='additive'`, which assumes the components are added together (trend + seasonality + residual).\n",
    "\n",
    "*   `figure = decomposition.plot()`: This line generates a plot showing the decomposed time series components.\n",
    "    *   `decomposition.plot()`:  This method creates a Matplotlib figure containing four subplots: the original time series, the trend component, the seasonal component, and the residual component. The function returns the `figure` object.\n",
    "\n",
    "*   `for ax in figure.get_axes():`: This loop iterates through each subplot (axis) within the generated figure.\n",
    "    *   `figure.get_axes()`:  This method returns a list of all the axes objects (subplots) in the figure.\n",
    "    *   `for ax in ...:`: The `for` loop allows you to access and modify each subplot individually.\n",
    "\n",
    "*   `ax.set_title(\"\")`: This line removes the default title from each subplot.  The original titles generated by `seasonal_decompose` can sometimes be redundant or unclear, so this step cleans up the plot.\n",
    "\n",
    "*   `plt.show()`: This displays the generated plot, showing the decomposed time series components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = '2005-12-31'\n",
    "train_df, valid_df = train_valid_split(df, cutoff_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddea732f",
   "metadata": {},
   "source": [
    "This code snippet splits your time series data into training and validation sets using the `train_valid_split` function we discussed earlier. \n",
    "\n",
    "*   `cutoff_date = '2005-12-31'`: This line defines a string variable named `cutoff_date` and assigns it the value \"2005-12-31\".  This date represents the point at which you want to split your data. All data on or before this date will be used for training, and all data after this date will be used for validation (testing).\n",
    "\n",
    "*   `train_df, valid_df = train_valid_split(df, cutoff_date)`: This line calls the `train_valid_split` function to perform the split.\n",
    "    *   `train_valid_split(df, cutoff_date)`:  This calls the function with two arguments:\n",
    "        *   `df`: The Pandas DataFrame containing your time series data (presumably loaded and prepared earlier). It’s expected to have a datetime index.\n",
    "        *   `cutoff_date`: The date string (\"2005-12-31\") that determines the split point.\n",
    "    *   `train_df, valid_df = ...`:  The `train_valid_split` function returns two DataFrames: the training set (`train_df`) and the validation set (`valid_df`). This line unpacks those returned values into separate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974eeed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1 = ExponentialSmoothing(train_df['value'].values, seasonal_periods=12, trend='mul', seasonal='mul')\n",
    "fit1 = fit1.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c314e7e8",
   "metadata": {},
   "source": [
    "This code snippet fits an Exponential Smoothing model to your training data:\n",
    "\n",
    "*   `fit1 = ExponentialSmoothing(train_df['value'].values, seasonal_periods=12, trend='mul', seasonal='mul')`: This line creates an instance of the `ExponentialSmoothing` model and configures its parameters.\n",
    "    *   `ExponentialSmoothing(...)`:  This initializes a new Exponential Smoothing object.\n",
    "    *   `train_df['value'].values`: Provides the training data to the model. It extracts the 'value' column from the `train_df` DataFrame and converts it into a NumPy array using `.values`. This is often necessary for compatibility with `statsmodels`.\n",
    "    *   `seasonal_periods=12`: Specifies that the time series has a seasonal pattern repeating every 12 periods (e.g., months).  This is crucial if your data exhibits seasonality.\n",
    "    *   `trend='mul'`: Sets the trend component to 'multiplicative'. This means the trend is modeled as a multiplicative factor applied to the level of the series. A multiplicative trend is appropriate when the magnitude of the trend increases or decreases over time.\n",
    "    *   `seasonal='mul'`: Sets the seasonal component to 'multiplicative'.  This means the seasonality is modeled as a multiplicative factor applied to the level of the series. This is often used when the amplitude of the seasonal fluctuations changes with the level of the series.\n",
    "\n",
    "*   `fit1 = fit1.fit()`: This line fits (trains) the Exponential Smoothing model to the training data.\n",
    "    *   `.fit()`:  This method estimates the optimal smoothing parameters (alpha, beta, gamma) that minimize the error between the model's predictions and the actual values in the training data. Because we didn’t specify those smoothing levels ourselves, `statsmodels` will optimize them for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae598ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1.params_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c98d45",
   "metadata": {},
   "source": [
    "Retrieve the  optimized parameter values (smoothing levels) from the fitted Holt-Winters exponential smoothing model (`fit1`):\n",
    "\n",
    "*   `fit1.params_formatted`: This accesses the `params_formatted` attribute of the fitted `ExponentialSmoothing` object (`fit1`).\n",
    "    *   `params_formatted`:  This is a Pandas Series that contains the optimized values for the smoothing parameters (alpha, beta, and gamma) used in the Holt-Winters model. It also includes their names and standard errors. The formatting makes it easy to read and understand the results of the optimization process.\n",
    "\n",
    "*   `level`: Represents alpha (α), the smoothing level for the level component of the time series.  It controls how much weight is given to recent observations when estimating the current level.\n",
    "*   `trend`: Represents beta (β), the smoothing factor for the trend component. It controls how much weight is given to recent changes in the slope (trend) of the series.\n",
    "*   `seasonal`: Represents gamma (γ), the smoothing factor for the seasonal component.  It controls how much weight is given to recent seasonal fluctuations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdf740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "prediction = fit1.forecast(len(valid_df)).copy()\n",
    "# compute the residuals\n",
    "xresiduals = valid_df['value'] - prediction\n",
    "plot_acf(xresiduals, lags = 25)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d7ebc",
   "metadata": {},
   "source": [
    "This part analyzes the residuals (the differences between actual and predicted values) from your Holt-Winters model to assess its performance.  \n",
    "\n",
    "**1. Forecasting on Validation Data:**\n",
    "\n",
    "*   `prediction = fit1.forecast(len(xvalid)).copy()`:\n",
    "    *   `fit1.forecast(len(xvalid))`: Uses the fitted Holt-Winters model (`fit1`) to generate forecasts for a number of periods equal to the length of your validation set (`xvalid`). This creates a Pandas Series containing the predicted values.\n",
    "    *   `.copy()`: Creates a copy of the forecast series.  This is important to avoid potential issues with modifying the original forecast data unintentionally.\n",
    "\n",
    "**2. Calculating Residuals:**\n",
    "\n",
    "*   `xresiduals = xvalid['value'] - prediction`:\n",
    "    *   `xvalid['value']`: Selects the actual values from the 'value' column of your validation set (`xvalid`).\n",
    "    *   `- prediction`: Subtracts the predicted values (from `prediction`) from the actual values. The result is a Pandas Series containing the residuals – the differences between what actually happened and what the model predicted.\n",
    "\n",
    "**3. Analyzing Residuals with ACF Plot:**\n",
    "\n",
    "*   `plot_acf(xresiduals, lags = 25)`:\n",
    "    *   `plot_acf(...)`:  This function from `statsmodels.graphics.tsaplots` creates an Autocorrelation Function (ACF) plot of the residuals. The ACF plot shows the correlation between the residuals and their lagged values.\n",
    "        *   `xresiduals`: Provides the series of residuals to be analyzed.\n",
    "        *   `lags = 25`: Specifies the maximum number of lags to include in the ACF plot.  A lag represents a time step back from the current observation.\n",
    "\n",
    "**4. Printing an Empty Line:**\n",
    "\n",
    "*   `print()`: Prints an empty line to add some visual separation between the ACF plot and any subsequent output. This is purely for formatting purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48ca309",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(xresiduals, lags = 25)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f77f9b",
   "metadata": {},
   "source": [
    "This code analyzes the residuals from your Holt-Winters model using a Partial Autocorrelation Function (PACF) plot to further assess its performance and identify potential areas for improvement.  \n",
    "\n",
    "*   `plot_pacf(xresiduals, lags = 25)`:\n",
    "    *   `plot_pacf(...)`: This function from `statsmodels.graphics.tsaplots` creates a Partial Autocorrelation Function (PACF) plot of the residuals. The PACF plot shows the correlation between the residuals and their lagged values *after removing the effects of intermediate lags*.  This helps to identify the direct relationship between an observation and its past values, without being influenced by other intervening observations.\n",
    "        *   `xresiduals`: Provides the series of residuals (calculated in the previous step) to be analyzed.\n",
    "        *   `lags = 25`: Specifies the maximum number of lags to include in the PACF plot.\n",
    "\n",
    "*   `print()`: Prints an empty line for visual separation, similar to the previous code snippet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1c2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_df['prediction'] = prediction\n",
    "valid_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243efb6c",
   "metadata": {},
   "source": [
    "The code adds the forecasted values as a new column to your validation DataFrame (`valid_df`) and then creates a plot showing both the actual values and the forecasts over time. \n",
    "\n",
    "*   `valid_df['prediction'] = prediction`:\n",
    "    *   `valid_df['prediction']`: Creates a new column named 'prediction' in the `valid_df` DataFrame.\n",
    "    *   `= prediction`: Assigns the forecasted values (stored in the `prediction` variable) to this new column.  Now, your validation DataFrame contains both the actual observed values ('value') and the corresponding predicted values ('prediction').\n",
    "\n",
    "*   `valid_df.plot()`:\n",
    "    *   `valid_df.plot()`: Creates a line plot of all numerical columns in the `valid_df` DataFrame. Since you have 'value' (the actual data) and 'prediction' (the forecasted data), Pandas will create a plot with two lines: one for the actual values and one for the predicted values.  The index of the DataFrame (which is the date/time) will be used as the x-axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f5fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_metrics(valid_df['value'], valid_df['prediction'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time-series-with-Konrad (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
