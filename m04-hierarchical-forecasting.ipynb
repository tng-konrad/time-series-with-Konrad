{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd1f7b8",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d1a570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kbanachewicz/Documents/time-series-with-Konrad/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasetsforecast.hierarchical import HierarchicalData\n",
    "from hierarchicalforecast.utils import aggregate\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from hierarchicalforecast.methods import  BottomUp, TopDown, MiddleOut, MinTrace, ERM\n",
    "from statsforecast.core import StatsForecast\n",
    "from statsforecast.models import AutoARIMA, Naive\n",
    "from hierarchicalforecast.evaluation import HierarchicalEvaluation\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Configuration & Settings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a6464",
   "metadata": {},
   "source": [
    "This section of code imports necessary libraries for time series forecasting, specifically focusing on hierarchical forecasting. \n",
    "\n",
    "It begins by importing modules from Python’s standard library: `warnings` to manage warning messages and `os` which provides a way of using operating system dependent functionality.\n",
    "\n",
    "Next, it imports several third-party packages. `numpy` is fundamental for numerical operations, while `pandas` is used for data manipulation and analysis with DataFrames. `matplotlib.pyplot` enables the creation of visualizations like plots and charts. \n",
    "\n",
    "The code then brings in specific tools from the `datasetsforecast`, `hierarchicalforecast`, `statsforecast`, and `sklearn` packages. From `datasetsforecast`, it imports `HierarchicalData` for handling hierarchical data structures.  From `hierarchicalforecast`, several modules are imported: `aggregate` for aggregating time series, `HierarchicalReconciliation` which is the core class for reconciliation methods, and various reconciliation strategies like `BottomUp`, `TopDown`, `MiddleOut`, `MinTrace`, and `ERM`. The `statsforecast` package provides tools for statistical forecasting; it imports `StatsForecast` as a central class and specific models such as `AutoARIMA` (automatic ARIMA model selection) and `Naive` (a simple baseline forecast). Finally, `hierarchicalforecast.evaluation` is used to assess the performance of hierarchical forecasts, and functions from `sklearn.metrics` (`mean_absolute_error`, `mean_squared_error`) are included for calculating error metrics.\n",
    "\n",
    "The final line suppresses `FutureWarning` messages, which can clutter output without necessarily indicating critical issues. This ensures a cleaner presentation of results during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f383de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general settings\n",
    "class CFG:\n",
    "    data_folder = './data/'\n",
    "    graph_folder = './graphs/'\n",
    "    img_dim1 = 20\n",
    "    img_dim2 = 10\n",
    "    SEED = 42\n",
    "    metric = 'rmse'\n",
    "\n",
    "\n",
    "# display style \n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "plt.rcParams[\"figure.figsize\"] = (CFG.img_dim1, CFG.img_dim2)\n",
    "\n",
    "np.random.seed(CFG.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e416be6f",
   "metadata": {},
   "source": [
    "This code segment defines general settings and adjusts the display style for subsequent operations, likely related to data analysis and visualization. \n",
    "\n",
    "A class named `CFG` is created to encapsulate configuration parameters. It specifies the directories for storing data (`data_folder`) and generated graphs (`graph_folder`).  It also sets dimensions for images (`img_dim1`, `img_dim2`), a random seed value (`SEED`) for reproducibility, and defines the evaluation metric to be used as root mean squared error (`metric`).\n",
    "\n",
    "Following this, the code modifies the default plotting style using `matplotlib.pyplot`. It applies the \"seaborn-v0_8\" style theme and sets the default figure size based on the dimensions defined in the `CFG` class. \n",
    "\n",
    "Finally, it initializes the NumPy random number generator with the seed value specified in `CFG.SEED`, ensuring that any randomized processes will produce consistent results across multiple runs of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea307f",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81800f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_metrics(y_true, y_pred, metric='rmse', precision = 2):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    if metric == 'rmse':\n",
    "        return np.round(np.sqrt(mean_squared_error(y_true, y_pred)), precision)\n",
    "    elif metric == 'mse':\n",
    "        return np.round(mean_squared_error(y_true, y_pred), precision)\n",
    "    elif metric == 'mae':\n",
    "        return np.round(mean_absolute_error(y_true, y_pred), precision)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported metric: {metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b62f8f",
   "metadata": {},
   "source": [
    "This code defines a function called `forecast_metrics` that calculates and returns forecast evaluation metrics.\n",
    "\n",
    "The function takes two arguments: `y_true`, representing the actual values, and `y_pred`, representing the predicted values. It also accepts optional parameters for the desired `metric` (defaulting to 'rmse') and the number of decimal places for rounding (`precision`, defaulting to 2).\n",
    "\n",
    "Inside the function, both input arrays are converted to NumPy arrays using `np.array()`.  A series of conditional statements then checks the value of the `metric` parameter. If it's 'rmse', the root mean squared error is calculated using `mean_squared_error` from scikit-learn, and the square root is taken before rounding to the specified precision. Similarly, if `metric` is 'mse', the mean squared error is directly computed and rounded.  If `metric` is 'mae', the mean absolute error is calculated and rounded. \n",
    "\n",
    "If an unsupported metric name is provided, a `ValueError` exception is raised with a descriptive message indicating which metric was not recognized. The function ultimately returns the calculated and rounded metric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676b4e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_forecasts(y_test_df, y_pred_df):\n",
    "    return pd.merge(y_test_df, y_pred_df, on=['ds', 'unique_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49486f1",
   "metadata": {},
   "source": [
    "This code defines a function named `merge_forecasts` that combines actual and predicted time series data into a single DataFrame.\n",
    "\n",
    "The function accepts two arguments: `y_test_df`, which is a pandas DataFrame containing the true (observed) values, and `y_pred_df`, a DataFrame holding the forecasted values. \n",
    "\n",
    "It uses the `pd.merge` function from the pandas library to join these two DataFrames based on common columns. The `on=['ds', 'unique_id']` argument specifies that the merge should be performed using the ‘ds’ ( representing date/timestamp) and ‘unique_id’ columns, which are assumed to uniquely identify each time series within the data. \n",
    "\n",
    "The function returns a new DataFrame where rows from `y_test_df` and `y_pred_df` are combined based on matching values in these specified columns, allowing for direct comparison of actual versus predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ea281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overall_error(df, actual_col, pred_col, metric='rmse'):\n",
    "    return forecast_metrics(df[actual_col], df[pred_col], metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fb4ef0",
   "metadata": {},
   "source": [
    "This code defines a function named `compute_overall_error` that calculates an overall error metric for a given DataFrame.\n",
    "\n",
    "The function accepts three arguments: `df`, which is the Pandas DataFrame containing both actual and predicted values; `actual_col`, specifying the name of the column in the DataFrame holding the true values; and `pred_col`, indicating the column with the forecasted values. It also takes an optional argument, `metric`, defaulting to 'rmse', that determines which error metric will be computed.\n",
    "\n",
    "The function’s core functionality is a single line: it calls the previously defined `forecast_metrics` function, passing in the actual and predicted value columns from the DataFrame (`df[actual_col]` and `df[pred_col]`, respectively) along with the specified `metric`. The result returned by `forecast_metrics` – the calculated error score – is then directly returned by `compute_overall_error`. Essentially, this function serves as a convenient wrapper to apply the `forecast_metrics` calculation to specific columns within a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b4153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_per_level(df, tags, actual_col, pred_col, metric='rmse'):\n",
    "    results = []\n",
    "    for level, ids in tags.items():\n",
    "        mask = df['unique_id'].isin(ids)\n",
    "        err = forecast_metrics(df.loc[mask, actual_col], df.loc[mask, pred_col], metric=metric)\n",
    "        results.append({\n",
    "            'level': level,\n",
    "            f'{metric}': err\n",
    "        })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad5cdb3",
   "metadata": {},
   "source": [
    "This code defines a function called `compute_error_per_level` that calculates error metrics for each level within a hierarchical dataset.\n",
    "\n",
    "The function takes five arguments: `df`, the Pandas DataFrame containing the data; `tags`, a dictionary where keys represent levels in the hierarchy and values are lists of unique identifiers belonging to each level; `actual_col`, the name of the column with actual values; `pred_col`, the name of the column with predicted values; and an optional `metric` argument (defaulting to 'rmse') specifying the error metric.\n",
    "\n",
    "The function initializes an empty list called `results`. It then iterates through each level and its corresponding IDs in the `tags` dictionary. Inside the loop, a boolean mask is created using `df['unique_id'].isin(ids)`, which selects rows from the DataFrame where the 'unique_id' column matches any of the IDs for the current level. \n",
    "\n",
    "The `forecast_metrics` function is then called with the filtered actual and predicted values (obtained using `.loc[mask, actual_col]` and `.loc[mask, pred_col]`) to calculate the error metric for that specific level. A dictionary containing the level name and the calculated error value is created and appended to the `results` list.\n",
    "\n",
    "Finally, after processing all levels, the function converts the `results` list into a Pandas DataFrame and returns it. This resulting DataFrame will have columns 'level' and the specified metric (e.g., 'rmse'), providing an overview of forecast accuracy at each hierarchical level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b842491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_baseline_vs_reconciled(df, tags, actual_col, baseline_col, reconciled_col, metric='rmse'):\n",
    "    results = []\n",
    "    for level, ids in tags.items():\n",
    "        mask = df['unique_id'].isin(ids)\n",
    "\n",
    "        baseline_err = forecast_metrics(df.loc[mask, actual_col], df.loc[mask, baseline_col], metric=metric)\n",
    "        reconciled_err = forecast_metrics(df.loc[mask, actual_col], df.loc[mask, reconciled_col], metric=metric)\n",
    "\n",
    "        results.append({\n",
    "            'level': level,\n",
    "            f'baseline_{metric}': baseline_err,\n",
    "            f'reconciled_{metric}': reconciled_err,\n",
    "            f'delta_{metric}': reconciled_err - baseline_err,\n",
    "            'improved': reconciled_err < baseline_err\n",
    "        })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec382b7",
   "metadata": {},
   "source": [
    "This code defines a function called `compare_baseline_vs_reconciled` that compares the performance of a baseline forecast against a reconciled forecast at each level of a hierarchical structure.\n",
    "\n",
    "The function takes six arguments: `df`, the Pandas DataFrame containing the data; `tags`, a dictionary defining the hierarchy (levels and their IDs); `actual_col`, the column with actual values; `baseline_col`, the column with baseline forecasts; `reconciled_col`, the column with reconciled forecasts; and an optional `metric` argument (defaulting to 'rmse') for evaluating performance.\n",
    "\n",
    "It initializes an empty list called `results`. The code then iterates through each level and its associated IDs in the `tags` dictionary. Inside the loop, a boolean mask is created using `df['unique_id'].isin(ids)` to select data belonging to the current level. \n",
    "\n",
    "The `forecast_metrics` function is called twice: once to calculate the error between actual values and the baseline forecasts (`baseline_err`), and again to calculate the error between actual values and the reconciled forecasts (`reconciled_err`). Both calculations use the specified `metric`.\n",
    "\n",
    "A dictionary is created containing the level name, the baseline error, the reconciled error, the difference (delta) between the two errors, and a boolean value indicating whether the reconciled forecast improved upon the baseline (i.e., if the reconciled error is less than the baseline error). This dictionary is appended to the `results` list.\n",
    "\n",
    "Finally, after processing all levels, the function converts the `results` list into a Pandas DataFrame and returns it. The resulting DataFrame provides a level-by-level comparison of the baseline and reconciled forecasts, including the performance improvement (or degradation) achieved by reconciliation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de43eda",
   "metadata": {},
   "source": [
    "# Groundwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d17061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M5 competition data - aggregated and prepared in https://github.com/tng-konrad/time-series-with-Konrad/blob/main/helper-m04.ipynb\n",
    "df = pd.read_csv(CFG.data_folder + 'm04_sales_data_prepared.csv')\n",
    "# add a (dummy) column for total level\n",
    "df['top_level'] = 'Total'\n",
    "# hierarchy structure: mid level: middle_level, bottom level: bottom_level\n",
    "df.rename(columns={'state_id': 'middle_level', 'store_id': 'bottom_level'}, inplace=True)\n",
    "# arrange columns\n",
    "df = df[['ds', 'top_level',  'middle_level', 'bottom_level', 'y']]\n",
    "# format date column\n",
    "df['ds'] = pd.to_datetime(df['ds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacb83ba",
   "metadata": {},
   "source": [
    "This code segment loads, prepares, and formats data for hierarchical forecasting, specifically using a dataset from the M5 competition.\n",
    "\n",
    "It begins by reading a CSV file named `m04_sales_data_prepared.csv` located in the directory specified by `CFG.data_folder` (defined earlier as `./data/`) into a Pandas DataFrame called `df`. The data preparation steps used to create this CSV are documented in a GitHub notebook referenced in the comment.\n",
    "\n",
    "Next, a new column named 'top_level' is added to the DataFrame and populated with the string \"Total\" for all rows. This creates a dummy top-level aggregation point for the hierarchical structure. \n",
    "\n",
    "The code then renames two existing columns: 'state_id' is renamed to 'middle_level', and 'store_id' is renamed to 'bottom_level'. These represent the intermediate and lowest levels of the hierarchy, respectively.\n",
    "\n",
    "Following this, the order of columns in the DataFrame is rearranged to be `['ds', 'top_level', 'middle_level', 'bottom_level', 'y']`, where 'ds' represents the date column and 'y' represents the target variable (sales data). \n",
    "\n",
    "Finally, the 'ds' column is converted from its original data type to a datetime object using `pd.to_datetime()`. This ensures that time series operations can be performed correctly on this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f00889ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>top_level</th>\n",
       "      <th>middle_level</th>\n",
       "      <th>bottom_level</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>Total</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>Total</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>Total</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA_3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds top_level middle_level bottom_level  y\n",
       "0 2014-01-01     Total           CA         CA_1  3\n",
       "1 2014-01-01     Total           CA         CA_2  0\n",
       "2 2014-01-01     Total           CA         CA_3  7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b988260d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "tags['top_level'] : ['Total']\n",
      "---\n",
      "tags['top_level/middle_level'] : ['Total/CA' 'Total/TX' 'Total/WI']\n",
      "---\n",
      "tags['top_level/middle_level/bottom_level'] : ['Total/CA/CA_1' 'Total/CA/CA_2' 'Total/CA/CA_3' 'Total/CA/CA_4'\n",
      " 'Total/TX/TX_1' 'Total/TX/TX_2' 'Total/TX/TX_3' 'Total/WI/WI_1'\n",
      " 'Total/WI/WI_2' 'Total/WI/WI_3']\n"
     ]
    }
   ],
   "source": [
    "# prepare hierarchical data\n",
    "hierarchy_levels = [\n",
    "    [\"top_level\"],  [\"top_level\", \"middle_level\"],  [\"top_level\", \"middle_level\", \"bottom_level\"] ]\n",
    "\n",
    "Y_hier_df, S_df, tags = aggregate(df=df, spec=hierarchy_levels)\n",
    "\n",
    "# print(\"S_df.shape\", S_df.shape)\n",
    "# print(\"Y_hier_df.shape\", Y_hier_df.shape)\n",
    "\n",
    "# quick check\n",
    "for k in tags.keys():\n",
    "    print('---')\n",
    "    print(f\"tags['{k}'] :\", tags[k])\n",
    "#     print(f\"tags['{k}'] shape:\", tags[k].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8865709b",
   "metadata": {},
   "source": [
    "This code prepares the data for hierarchical forecasting using the `aggregate` function from the `hierarchicalforecast` library.\n",
    "\n",
    "First, a list called `hierarchy_levels` is defined. This list specifies the levels of the hierarchy to be created. Each element in the list represents a level and contains the names of the columns that define that level. For example, `[\"top_level\"]` defines the top-most level using only the 'top_level' column, while `[\"top_level\", \"middle_level\", \"bottom_level\"]` defines the bottom-most level using all three hierarchical columns.\n",
    "\n",
    "The `aggregate` function is then called with the DataFrame `df` and the `hierarchy_levels` specification. This function restructures the data into a format suitable for hierarchical forecasting, returning three objects: `Y_hier_df`, `S_df`, and `tags`.  `Y_hier_df` contains the time series data aggregated at each level of the hierarchy. `S_df` likely holds static information about the hierarchy structure. `tags` is a dictionary that maps each hierarchical level to a list of unique identifiers (IDs) belonging to that level.\n",
    "\n",
    "The code then prints the shapes of `S_df` and `Y_hier_df` to provide an initial check on the data dimensions after aggregation. \n",
    "\n",
    "Finally, it iterates through the keys (levels) in the `tags` dictionary and prints each level's name along with the corresponding list of IDs and its shape. This provides a quick verification that the hierarchy has been constructed correctly and that each level contains the expected number of unique identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c6e3ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 7 \n",
    "\n",
    "Y_test_df = Y_hier_df.groupby(\"unique_id\", as_index=False).tail(horizon)\n",
    "Y_train_df = Y_hier_df.drop(Y_test_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ebc2e",
   "metadata": {},
   "source": [
    "This code segment splits the hierarchical time series data into training and testing sets based on a specified forecast horizon.\n",
    "\n",
    "First, the `horizon` variable is set to 7, indicating that the forecasts will be made for the next 7 time steps.\n",
    "\n",
    "Then, `Y_test_df` is created by grouping the `Y_hier_df` DataFrame (which contains the aggregated time series data) by 'unique_id' and selecting the last `horizon` rows from each group using `.tail(horizon)`. This effectively creates a test set consisting of the most recent 7 observations for each unique time series in the hierarchy. The `as_index=False` argument prevents the 'unique_id' column from becoming the index of the resulting DataFrame.\n",
    "\n",
    "Finally, `Y_train_df` is created by removing the rows present in `Y_test_df` from `Y_hier_df` using `.drop(Y_test_df.index)`. This leaves a training set containing all time series data except for the last 7 observations of each series, which are reserved for testing.TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39fd0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute base auto-ARIMA predictions\n",
    "model = AutoARIMA(season_length=7)\n",
    "fcst = StatsForecast(models=[model], freq=\"D\", n_jobs=-1)\n",
    "Y_hat_df = fcst.forecast(df=Y_train_df, h=4, fitted=True)\n",
    "Y_fitted_df = fcst.forecast_fitted_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3078d8d3",
   "metadata": {},
   "source": [
    "This code computes baseline forecasts using an AutoARIMA model and the `statsforecast` library.\n",
    "\n",
    "First, an `AutoARIMA` model is initialized with a `season_length` of 7, indicating that the time series data exhibits weekly seasonality.\n",
    "\n",
    "Next, a `StatsForecast` object is created. This object manages the forecasting process using one or more models. In this case, it's configured to use only the `AutoARIMA` model defined earlier. The `freq=\"D\"` argument specifies that the data has daily frequency, and `n_jobs=-1` tells `statsforecast` to use all available CPU cores for parallel processing.\n",
    "\n",
    "The `fcst.forecast()` method is then called with `Y_train_df` (the training data) as input and a forecast horizon of `h=4`. This generates forecasts for the next 4 time steps for each series in the training set. The `fitted=True` argument instructs the model to also store the fitted values from the training period.  The resulting DataFrame containing the forecasted values is stored in `Y_hat_df`.\n",
    "\n",
    "Finally, `fcst.forecast_fitted_values()` retrieves the fitted values (in-sample predictions) generated by the AutoARIMA model during the training process and stores them in `Y_fitted_df`. These fitted values represent the model's best estimate of the historical data based on the training set.TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecc70386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>AutoARIMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total</td>\n",
       "      <td>2016-05-16</td>\n",
       "      <td>12</td>\n",
       "      <td>14.092568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>11</td>\n",
       "      <td>14.102201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>2016-05-18</td>\n",
       "      <td>22</td>\n",
       "      <td>14.102201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds   y  AutoARIMA\n",
       "0     Total 2016-05-16  12  14.092568\n",
       "1     Total 2016-05-17  11  14.102201\n",
       "2     Total 2016-05-18  22  14.102201"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmat = merge_forecasts(Y_test_df, Y_hat_df)\n",
    "\n",
    "# keep track of the real / prediction column name\n",
    "actual_col = 'y'\n",
    "baseline_col = xmat.columns[-1]\n",
    "\n",
    "xmat.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab57710",
   "metadata": {},
   "source": [
    "This code merges the actual test data with the baseline forecasts generated by the AutoARIMA model and prepares for comparison.\n",
    "\n",
    "The `merge_forecasts` function is called with `Y_test_df` (the actual values from the test set) and `Y_hat_df` (the forecasted values). This function combines the two DataFrames, aligning them based on the 'unique_id' and time index to create a single DataFrame (`xmat`) containing both the true values and the corresponding forecasts.\n",
    "\n",
    "The code then defines variables `actual_col` and `baseline_col`.  `actual_col` is set to 'y', which represents the column name for the actual observed values in the original data. `baseline_col` is assigned the name of the last column in the merged DataFrame (`xmat`), which corresponds to the forecasted values generated by the AutoARIMA model.\n",
    "\n",
    "Finally, `xmat.head(3)` displays the first three rows of the merged DataFrame `xmat`. This allows for a quick inspection of the data structure and confirms that the actual and predicted values have been correctly aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "486d31b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall rmse : 2.15\n",
      "top_level rmse: 5.06\n",
      "top_level/middle_level rmse: 2.45\n",
      "top_level/middle_level/bottom_level rmse: 1.45\n"
     ]
    }
   ],
   "source": [
    "overall_rmse = forecast_metrics(xmat['y'], xmat[baseline_col], metric = CFG.metric)\n",
    "print(f'Overall {CFG.metric} : {overall_rmse}')\n",
    "\n",
    "\n",
    "for k, ids in tags.items():\n",
    "    mask = xmat['unique_id'].isin(ids)\n",
    "    k_metrics = forecast_metrics(xmat.loc[mask, 'y'], xmat.loc[mask, baseline_col])\n",
    "    print(f\"{k} {CFG.metric}: {k_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad37d0",
   "metadata": {},
   "source": [
    "This code calculates and prints overall and per-level evaluation metrics for the AutoARIMA baseline forecasts.\n",
    "\n",
    "First, it computes the overall Root Mean Squared Error (RMSE) – or whatever metric is specified in `CFG.metric` – between the actual values (`xmat['y']`) and the baseline forecasts (`xmat[baseline_col]`) using the `forecast_metrics` function. The result is stored in the `overall_rmse` variable, and then printed to the console with a descriptive message.\n",
    "\n",
    "Next, it iterates through each level of the hierarchy defined by the `tags` dictionary. Inside the loop, a boolean mask (`mask`) is created to select rows from the `xmat` DataFrame that belong to the current hierarchical level (based on 'unique_id'). \n",
    "\n",
    "The `forecast_metrics` function is then called with the actual values and baseline forecasts for the selected level (using `.loc[mask, 'y']` and `.loc[mask, baseline_col]`). The resulting metric value (`k_metrics`) is printed to the console along with the level name and the metric type specified in `CFG.metric`. This provides a breakdown of forecast accuracy at each level of the hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20b388f",
   "metadata": {},
   "source": [
    "# Hierarchical methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcbecee",
   "metadata": {},
   "source": [
    "## BottomUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ca4aca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoARIMA</th>\n",
       "      <th>AutoARIMA/BottomUp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total</td>\n",
       "      <td>2016-05-16</td>\n",
       "      <td>14.092568</td>\n",
       "      <td>13.943087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>14.102201</td>\n",
       "      <td>13.327107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>2016-05-18</td>\n",
       "      <td>14.102201</td>\n",
       "      <td>13.409471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  AutoARIMA  AutoARIMA/BottomUp\n",
       "0     Total 2016-05-16  14.092568           13.943087\n",
       "1     Total 2016-05-17  14.102201           13.327107\n",
       "2     Total 2016-05-18  14.102201           13.409471"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconcilers = [BottomUp()] \n",
    "\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "\n",
    "Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df, Y_df=Y_fitted_df, S_df=S_df, tags=tags)\n",
    "\n",
    "# column name of the reconciled forecasts\n",
    "reconciled_col = Y_rec_df.columns[-1]\n",
    "\n",
    "Y_rec_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f69004",
   "metadata": {},
   "source": [
    "This code performs hierarchical reconciliation to improve forecast accuracy by leveraging the hierarchical structure of the data.\n",
    "\n",
    "First, a list called `reconcilers` is created containing a single reconciliation method: `BottomUp()`. This indicates that the bottom-up reconciliation approach will be used, where forecasts are aggregated from lower levels to higher levels in the hierarchy.\n",
    "\n",
    "Next, a `HierarchicalReconciliation` object (`hrec`) is initialized with the specified list of reconcilers. \n",
    "\n",
    "The core reconciliation step is then performed using `hrec.reconcile()`. This function takes four arguments: `Y_hat_df` (the forecasts from the base model), `Y_df` (the fitted values from the base model, used for adjusting the reconciled forecasts), `S_df` (static information about the hierarchy structure), and `tags` (the dictionary defining the hierarchical levels). The function reconciles the base forecasts to ensure consistency across all levels of the hierarchy.  The resulting DataFrame containing the reconciled forecasts is stored in `Y_rec_df`.\n",
    "\n",
    "The code then determines the name of the column in `Y_rec_df` that contains the reconciled forecasts and assigns it to the variable `reconciled_col`. This is done by accessing the last column of the DataFrame. \n",
    "\n",
    "Finally, `Y_rec_df.head(3)` displays the first three rows of the reconciled forecast DataFrame, allowing for a quick inspection of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b60b0e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge reconciled forecasts with test data\n",
    "df_eval = merge_forecasts(Y_test_df, Y_rec_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f80d5f",
   "metadata": {},
   "source": [
    "This code merges the actual test data (`Y_test_df`) with the reconciled forecasts (`Y_rec_df`) to prepare for evaluating the performance of the reconciliation process.\n",
    "\n",
    "The `merge_forecasts` function is called with `Y_test_df` and `Y_rec_df` as arguments. This function combines the two DataFrames, aligning them based on the 'unique_id' and time index to create a single DataFrame (`df_eval`) containing both the true values from the test set and the corresponding reconciled forecasts. The resulting DataFrame is ready for calculating evaluation metrics that compare the reconciled forecasts against the actual observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30e5c67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE: 2.1500\n",
      "Reconciled RMSE: 2.1800\n",
      "Delta RMSE: 0.0300\n"
     ]
    }
   ],
   "source": [
    "metric = 'rmse'\n",
    "\n",
    "baseline_overall = compute_overall_error(df_eval, actual_col, baseline_col, metric)\n",
    "reconciled_overall = compute_overall_error(df_eval, actual_col, reconciled_col, metric)\n",
    "\n",
    "print(f\"Baseline {metric.upper()}: {baseline_overall:.4f}\")\n",
    "print(f\"Reconciled {metric.upper()}: {reconciled_overall:.4f}\")\n",
    "print(f\"Delta {metric.upper()}: {reconciled_overall - baseline_overall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74348cfe",
   "metadata": {},
   "source": [
    "This code calculates and prints the overall evaluation metrics for both the baseline forecasts and the reconciled forecasts.\n",
    "\n",
    "First, the `metric` variable is set to 'rmse', specifying that Root Mean Squared Error will be used as the evaluation metric.\n",
    "\n",
    "Then, `compute_overall_error` is called twice: once to calculate the overall RMSE for the baseline forecasts (`baseline_overall`), using the actual values (`actual_col`) and the baseline forecast column (`baseline_col`); and again to calculate the overall RMSE for the reconciled forecasts (`reconciled_overall`), using the actual values and the reconciled forecast column (`reconciled_col`).\n",
    "\n",
    "Finally, the code prints the calculated metrics to the console. It displays the baseline RMSE, the reconciled RMSE, and the difference (delta) between the two, formatted to four decimal places using f-strings (`:.4f`). This allows for a direct comparison of the performance of the baseline forecasts versus the reconciled forecasts across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3480c8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>baseline_rmse</th>\n",
       "      <th>reconciled_rmse</th>\n",
       "      <th>delta_rmse</th>\n",
       "      <th>improved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top_level</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>top_level/middle_level</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>top_level/middle_level/bottom_level</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 level  baseline_rmse  reconciled_rmse  \\\n",
       "0                            top_level           5.06             5.14   \n",
       "1               top_level/middle_level           2.45             2.52   \n",
       "2  top_level/middle_level/bottom_level           1.45             1.45   \n",
       "\n",
       "   delta_rmse  improved  \n",
       "0        0.08     False  \n",
       "1        0.07     False  \n",
       "2        0.00     False  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_level_baseline = compute_error_per_level(df_eval, tags, actual_col, baseline_col, metric)\n",
    "per_level_reconciled = compute_error_per_level(df_eval, tags, actual_col, reconciled_col, metric)\n",
    "\n",
    "\n",
    "comparison_df = compare_baseline_vs_reconciled(\n",
    "    df=df_eval,\n",
    "    tags=tags,\n",
    "    actual_col=actual_col,\n",
    "    baseline_col=baseline_col,\n",
    "    reconciled_col=reconciled_col,\n",
    "    metric=metric\n",
    ")\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe6f6e",
   "metadata": {},
   "source": [
    "This code calculates and presents a detailed comparison of the baseline and reconciled forecasts at each level of the hierarchy.\n",
    "\n",
    "First, `compute_error_per_level` is called twice: once to calculate the RMSE (or specified metric) for the baseline forecasts at each hierarchical level (`per_level_baseline`), and again to do the same for the reconciled forecasts (`per_level_reconciled`). Both calls use the evaluation DataFrame `df_eval`, the hierarchy definition in `tags`, and the appropriate forecast columns.\n",
    "\n",
    "Next, the `compare_baseline_vs_reconciled` function is called with all necessary arguments: the evaluation DataFrame `df_eval`, the hierarchy structure `tags`, the actual value column name `actual_col`, the baseline forecast column name `baseline_col`, the reconciled forecast column name `reconciled_col`, and the chosen metric `metric`. This function generates a DataFrame (`comparison_df`) that summarizes the performance comparison at each level, including the baseline error, reconciled error, the difference between them (delta), and an indicator of whether reconciliation improved accuracy.\n",
    "\n",
    "Finally, the code displays the contents of the `comparison_df` DataFrame. This provides a comprehensive view of how reconciliation affects forecast accuracy across different levels of the hierarchy, allowing for a detailed assessment of its effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4ac838",
   "metadata": {},
   "source": [
    "## MiddleOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16f7dfbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoARIMA</th>\n",
       "      <th>AutoARIMA/BottomUp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total</td>\n",
       "      <td>2016-05-16</td>\n",
       "      <td>14.092568</td>\n",
       "      <td>13.943087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>14.102201</td>\n",
       "      <td>13.327107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>2016-05-18</td>\n",
       "      <td>14.102201</td>\n",
       "      <td>13.409471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  AutoARIMA  AutoARIMA/BottomUp\n",
       "0     Total 2016-05-16  14.092568           13.943087\n",
       "1     Total 2016-05-17  14.102201           13.327107\n",
       "2     Total 2016-05-18  14.102201           13.409471"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconcilers = [\n",
    "    MiddleOut(middle_level = 'top_level/middle_level', top_down_method='forecast_proportions')\n",
    "]\n",
    "Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df, Y_df=Y_fitted_df, S_df=S_df, tags=tags)\n",
    "\n",
    "# column name of the reconciled forecasts\n",
    "reconciled_col = Y_rec_df.columns[-1]\n",
    "\n",
    "Y_rec_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e1febff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge reconciled forecasts with test data\n",
    "df_eval = merge_forecasts(Y_test_df, Y_rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03b7132c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE: 2.1500\n",
      "Reconciled RMSE: 2.1800\n",
      "Delta RMSE: 0.0300\n"
     ]
    }
   ],
   "source": [
    "metric = 'rmse'\n",
    "\n",
    "baseline_overall = compute_overall_error(df_eval, actual_col, baseline_col, metric)\n",
    "reconciled_overall = compute_overall_error(df_eval, actual_col, reconciled_col, metric)\n",
    "\n",
    "print(f\"Baseline {metric.upper()}: {baseline_overall:.4f}\")\n",
    "print(f\"Reconciled {metric.upper()}: {reconciled_overall:.4f}\")\n",
    "print(f\"Delta {metric.upper()}: {reconciled_overall - baseline_overall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "677cdce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>baseline_rmse</th>\n",
       "      <th>reconciled_rmse</th>\n",
       "      <th>delta_rmse</th>\n",
       "      <th>improved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top_level</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>top_level/middle_level</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>top_level/middle_level/bottom_level</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 level  baseline_rmse  reconciled_rmse  \\\n",
       "0                            top_level           5.06             5.14   \n",
       "1               top_level/middle_level           2.45             2.52   \n",
       "2  top_level/middle_level/bottom_level           1.45             1.45   \n",
       "\n",
       "   delta_rmse  improved  \n",
       "0        0.08     False  \n",
       "1        0.07     False  \n",
       "2        0.00     False  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_level_baseline = compute_error_per_level(df_eval, tags, actual_col, baseline_col, metric)\n",
    "per_level_reconciled = compute_error_per_level(df_eval, tags, actual_col, reconciled_col, metric)\n",
    "\n",
    "\n",
    "comparison_df = compare_baseline_vs_reconciled(\n",
    "    df=df_eval,\n",
    "    tags=tags,\n",
    "    actual_col=actual_col,\n",
    "    baseline_col=baseline_col,\n",
    "    reconciled_col=reconciled_col,\n",
    "    metric=metric\n",
    ")\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4992b0",
   "metadata": {},
   "source": [
    "## TopDown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f455e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoARIMA</th>\n",
       "      <th>AutoARIMA/TopDown_method-forecast_proportions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total</td>\n",
       "      <td>2016-05-16</td>\n",
       "      <td>14.092568</td>\n",
       "      <td>14.092568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>14.102201</td>\n",
       "      <td>14.102201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>2016-05-18</td>\n",
       "      <td>14.102201</td>\n",
       "      <td>14.102201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  AutoARIMA  \\\n",
       "0     Total 2016-05-16  14.092568   \n",
       "1     Total 2016-05-17  14.102201   \n",
       "2     Total 2016-05-18  14.102201   \n",
       "\n",
       "   AutoARIMA/TopDown_method-forecast_proportions  \n",
       "0                                      14.092568  \n",
       "1                                      14.102201  \n",
       "2                                      14.102201  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconcilers = [\n",
    "   TopDown(method='forecast_proportions')]\n",
    "\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "\n",
    "Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df, Y_df=Y_fitted_df, S_df=S_df, tags=tags)\n",
    "\n",
    "# column name of the reconciled forecasts\n",
    "reconciled_col = Y_rec_df.columns[-1]\n",
    "\n",
    "Y_rec_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ff809b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge reconciled forecasts with test data\n",
    "df_eval = merge_forecasts(Y_test_df, Y_rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "498d2ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE: 2.1500\n",
      "Reconciled RMSE: 2.1400\n",
      "Delta RMSE: -0.0100\n"
     ]
    }
   ],
   "source": [
    "metric = 'rmse'\n",
    "\n",
    "baseline_overall = compute_overall_error(df_eval, actual_col, baseline_col, metric)\n",
    "reconciled_overall = compute_overall_error(df_eval, actual_col, reconciled_col, metric)\n",
    "\n",
    "print(f\"Baseline {metric.upper()}: {baseline_overall:.4f}\")\n",
    "print(f\"Reconciled {metric.upper()}: {reconciled_overall:.4f}\")\n",
    "print(f\"Delta {metric.upper()}: {reconciled_overall - baseline_overall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f78ba9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>baseline_rmse</th>\n",
       "      <th>reconciled_rmse</th>\n",
       "      <th>delta_rmse</th>\n",
       "      <th>improved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top_level</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>top_level/middle_level</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.43</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>top_level/middle_level/bottom_level</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.44</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 level  baseline_rmse  reconciled_rmse  \\\n",
       "0                            top_level           5.06             5.06   \n",
       "1               top_level/middle_level           2.45             2.43   \n",
       "2  top_level/middle_level/bottom_level           1.45             1.44   \n",
       "\n",
       "   delta_rmse  improved  \n",
       "0        0.00     False  \n",
       "1       -0.02      True  \n",
       "2       -0.01      True  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_level_baseline = compute_error_per_level(df_eval, tags, actual_col, baseline_col, metric)\n",
    "per_level_reconciled = compute_error_per_level(df_eval, tags, actual_col, reconciled_col, metric)\n",
    "\n",
    "\n",
    "comparison_df = compare_baseline_vs_reconciled(\n",
    "    df=df_eval,\n",
    "    tags=tags,\n",
    "    actual_col=actual_col,\n",
    "    baseline_col=baseline_col,\n",
    "    reconciled_col=reconciled_col,\n",
    "    metric=metric\n",
    ")\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdd916f",
   "metadata": {},
   "source": [
    "## MinTrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f2a224e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoARIMA</th>\n",
       "      <th>AutoARIMA/MinTrace_method-ols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total</td>\n",
       "      <td>2016-05-16</td>\n",
       "      <td>14.092568</td>\n",
       "      <td>14.050535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>14.102201</td>\n",
       "      <td>13.992761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>2016-05-18</td>\n",
       "      <td>14.102201</td>\n",
       "      <td>13.970089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  AutoARIMA  AutoARIMA/MinTrace_method-ols\n",
       "0     Total 2016-05-16  14.092568                      14.050535\n",
       "1     Total 2016-05-17  14.102201                      13.992761\n",
       "2     Total 2016-05-18  14.102201                      13.970089"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconcilers = [\n",
    "    MinTrace(method='ols'),\n",
    "]\n",
    "\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "\n",
    "\n",
    "Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df, Y_df=Y_fitted_df, S_df=S_df, tags=tags)\n",
    "\n",
    "# column name of the reconciled forecasts\n",
    "reconciled_col = Y_rec_df.columns[-1]\n",
    "\n",
    "Y_rec_df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6055a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge reconciled forecasts with test data\n",
    "df_eval = merge_forecasts(Y_test_df, Y_rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "681fa3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE: 2.1500\n",
      "Reconciled RMSE: 2.1500\n",
      "Delta RMSE: 0.0000\n"
     ]
    }
   ],
   "source": [
    "metric = 'rmse'\n",
    "\n",
    "baseline_overall = compute_overall_error(df_eval, actual_col, baseline_col, metric)\n",
    "reconciled_overall = compute_overall_error(df_eval, actual_col, reconciled_col, metric)\n",
    "\n",
    "print(f\"Baseline {metric.upper()}: {baseline_overall:.4f}\")\n",
    "print(f\"Reconciled {metric.upper()}: {reconciled_overall:.4f}\")\n",
    "print(f\"Delta {metric.upper()}: {reconciled_overall - baseline_overall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "570b3af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>baseline_rmse</th>\n",
       "      <th>reconciled_rmse</th>\n",
       "      <th>delta_rmse</th>\n",
       "      <th>improved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top_level</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>top_level/middle_level</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>top_level/middle_level/bottom_level</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.44</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 level  baseline_rmse  reconciled_rmse  \\\n",
       "0                            top_level           5.06             5.07   \n",
       "1               top_level/middle_level           2.45             2.45   \n",
       "2  top_level/middle_level/bottom_level           1.45             1.44   \n",
       "\n",
       "   delta_rmse  improved  \n",
       "0        0.01     False  \n",
       "1        0.00     False  \n",
       "2       -0.01      True  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_level_baseline = compute_error_per_level(df_eval, tags, actual_col, baseline_col, metric)\n",
    "per_level_reconciled = compute_error_per_level(df_eval, tags, actual_col, reconciled_col, metric)\n",
    "\n",
    "\n",
    "comparison_df = compare_baseline_vs_reconciled(\n",
    "    df=df_eval,\n",
    "    tags=tags,\n",
    "    actual_col=actual_col,\n",
    "    baseline_col=baseline_col,\n",
    "    reconciled_col=reconciled_col,\n",
    "    metric=metric\n",
    ")\n",
    "\n",
    "comparison_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time-series-with-Konrad (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
